defmodule CadetWeb.ChatController do
  @moduledoc """
  Handles the chatbot conversation API endpoints.
  Each user has exactly one conversation.
  """
  use CadetWeb, :controller
  use PhoenixSwagger
  require Logger

  alias Cadet.Chatbot.{Conversation, LlmConversations}
  @max_content_size 1000

  def init_chat(conn, _params) do
    user = conn.assigns.current_user
    Logger.info("Initializing chat for user #{user.id}")

    # Get existing conversation for user or create a new one (one per user)
    case LlmConversations.get_or_create_conversation(user.id) do
      {:ok, conversation} ->
        Logger.info(
          "Chat initialized successfully for user #{user.id}. Conversation ID: #{conversation.id}."
        )

        conn
        |> put_status(:ok)
        |> render("conversation_init.json", %{
          conversation_id: conversation.id,
          messages: conversation.messages,
          max_content_size: @max_content_size
        })

      {:error, error_message} ->
        Logger.error("Failed to initialize chat for user #{user.id}. Error: #{error_message}.")
        send_resp(conn, :unprocessable_entity, error_message)
    end
  end

  swagger_path :chat do
    put("/chat")

    summary("A wrapper for client that send queries to LLMs")

    security([%{JWT: []}])

    consumes("application/json")

    parameters do
      message(
        :body,
        :list,
        "User message to send to the chatbot. Each user has a single conversation that is automatically used."
      )
    end

    response(200, "OK")
    response(400, "Missing or invalid parameter(s)")
    response(401, "Unauthorized")
    response(404, "No conversation found for user")
    response(422, "Message exceeds the maximum allowed length")
    response(500, "When OpenAI API returns an error")
  end

  def chat(
        conn,
        %{
          "message" => user_message,
          "section" => section,
          "initialContext" => visible_text
        }
      )
      when is_binary(user_message) and is_binary(section) and is_binary(visible_text) do
    user = conn.assigns.current_user

    Logger.info(
      "Processing chat message for user #{user.id}. Message length: #{String.length(user_message)}."
    )

    # User is locked to a single conversation - fetch it by user_id only
    with true <- String.length(user_message) <= @max_content_size || {:error, :message_too_long},
         {:ok, conversation} <- LlmConversations.get_conversation_for_user(user.id),
         {:ok, updated_conversation} <-
           LlmConversations.add_message(conversation, "user", user_message),
         system_prompt <- Cadet.Chatbot.PromptBuilder.build_prompt(section, visible_text),
         payload <- generate_payload(updated_conversation, system_prompt) do
      case OpenAI.chat_completion(model: "gpt-4", messages: payload) do
        {:ok, result_map} ->
          choices = Map.get(result_map, :choices, [])

          bot_message =
            case choices do
              [first | _] -> first["message"]["content"]
              _ -> nil
            end

          if is_nil(bot_message) do
            Logger.error("OpenAI returned empty choices for user #{user.id}")
            LlmConversations.add_error_message(updated_conversation)
            send_resp(conn, 500, "No response from AI")
          else
            case LlmConversations.add_message(updated_conversation, "assistant", bot_message) do
              {:ok, _} ->
                Logger.info(
                  "Chat message processed successfully for user #{user.id}, conversation #{conversation.id}."
                )

                render(conn, "conversation.json", %{
                  conversation_id: conversation.id,
                  response: bot_message
                })

              {:error, error_message} ->
                Logger.error(
                  "Failed to save bot response for user #{user.id}, conversation #{conversation.id}: #{error_message}."
                )

                send_resp(conn, 500, error_message)
            end
          end

        {:error, reason} ->
          error_message = get_in(reason, ["error", "message"]) || "Unknown OpenAI error"

          Logger.error(
            "OpenAI API error for user #{user.id}, conversation #{conversation.id}: #{error_message}."
          )

          LlmConversations.add_error_message(updated_conversation)
          send_resp(conn, 500, error_message)
      end
    else
      {:error, :message_too_long} ->
        Logger.error(
          "Message too long for user #{user.id}. Length: #{String.length(user_message)}."
        )

        send_resp(
          conn,
          :unprocessable_entity,
          "Message exceeds the maximum allowed length of #{@max_content_size}"
        )

      {:error, {:not_found, error_message}} ->
        Logger.error("No conversation found for user #{user.id}. User must init_chat first.")

        send_resp(conn, :not_found, error_message)

      {:error, error_message} ->
        Logger.error("An error occurred for user #{user.id}. Error: #{error_message}.")
        send_resp(conn, 500, error_message)
    end
  end

  def chat(conn, _params) do
    Logger.error("Chat request failed due to missing parameters.")
    send_resp(conn, :bad_request, "Missing or invalid parameter(s)")
  end

  @context_size 10

  @spec generate_payload(Conversation.t(), String.t()) :: list(map())
  defp generate_payload(conversation, system_prompt) do
    system_context = [%{role: "system", content: system_prompt}]
    # Only get the last 10 messages into the context
    messages_payload =
      conversation.messages
      |> Enum.reverse()
      |> Enum.take(@context_size)
      |> Enum.map(&Map.take(&1, [:role, :content, "role", "content"]))
      |> Enum.reverse()

    system_context ++ messages_payload
  end

  def max_content_length, do: @max_content_size

  @guest_cookie "sa_guest_uuid"
  @guest_cookie_max_age 7 * 24 * 60 * 60

  def init_guest_chat(conn, _params) do
    guest_uuid = get_or_create_guest_uuid(conn)
    Logger.debug("Initializing guest chat for #{guest_uuid}")

    case LlmConversations.get_or_create_conversation_for_guest(guest_uuid) do
      {:ok, conversation} ->
        Logger.debug(
          "Guest chat initialized. Guest: #{guest_uuid}, Conversation: #{conversation.id}"
        )

        conn
        |> put_guest_cookie(guest_uuid)
        |> put_status(:ok)
        |> render("conversation_init.json", %{
          conversation_id: conversation.id,
          messages: conversation.messages,
          max_content_size: @max_content_size
        })

      {:error, error_message} ->
        Logger.error("Failed to init guest chat for #{guest_uuid}: #{error_message}")
        send_resp(conn, :unprocessable_entity, error_message)
    end
  end

  def guest_chat(
        conn,
        %{
          "message" => user_message,
          "section" => section,
          "initialContext" => visible_text
        }
      )
      when is_binary(user_message) and is_binary(section) and is_binary(visible_text) do
    case fetch_guest_uuid(conn) do
      {:error, :no_guest_uuid} ->
        Logger.error("Guest chat request missing guest UUID cookie.")
        send_resp(conn, :unauthorized, "Guest session not found. Please initialise chat first.")

      {:ok, guest_uuid} ->
        Logger.debug(
          "Processing guest chat message. Guest: #{guest_uuid}, length: #{String.length(user_message)}"
        )

        with true <-
               String.length(user_message) <= @max_content_size || {:error, :message_too_long},
             {:ok, conversation} <- LlmConversations.get_conversation_for_guest(guest_uuid),
             {:ok, updated_conversation} <-
               LlmConversations.add_message(conversation, "user", user_message),
             system_prompt <-
               Cadet.Chatbot.PromptBuilder.build_prompt(section, visible_text),
             payload <- generate_payload(updated_conversation, system_prompt) do
          case OpenAI.chat_completion(model: "gpt-4", messages: payload) do
            {:ok, result_map} ->
              choices = Map.get(result_map, :choices, [])

              bot_message =
                case choices do
                  [first | _] -> first["message"]["content"]
                  _ -> nil
                end

              if is_nil(bot_message) do
                Logger.error("OpenAI returned empty choices for guest #{guest_uuid}")
                LlmConversations.add_error_message(updated_conversation)
                send_resp(conn, 500, "No response from AI")
              else
                case LlmConversations.add_message(updated_conversation, "assistant", bot_message) do
                  {:ok, _} ->
                    Logger.debug(
                      "Guest chat processed. Guest: #{guest_uuid}, Conversation: #{conversation.id}"
                    )

                    conn
                    |> put_guest_cookie(guest_uuid)
                    |> render("conversation.json", %{
                      conversation_id: conversation.id,
                      response: bot_message
                    })

                  {:error, error_message} ->
                    Logger.error(
                      "Failed to save guest bot response. Guest: #{guest_uuid}: #{error_message}"
                    )

                    send_resp(conn, 500, error_message)
                end
              end

            {:error, reason} ->
              error_message = get_in(reason, ["error", "message"]) || "Unknown OpenAI error"

              Logger.error(
                "OpenAI API error for guest #{guest_uuid}, conversation #{conversation.id}: #{error_message}"
              )

              LlmConversations.add_error_message(updated_conversation)
              send_resp(conn, 500, error_message)
          end
        else
          {:error, :message_too_long} ->
            send_resp(
              conn,
              :unprocessable_entity,
              "Message exceeds the maximum allowed length of #{@max_content_size}"
            )

          {:error, {:not_found, error_message}} ->
            send_resp(conn, :not_found, error_message)

          {:error, error_message} ->
            send_resp(conn, 500, error_message)
        end
    end
  end

  def guest_chat(conn, _params) do
    Logger.error("Guest chat request failed due to missing parameters.")
    send_resp(conn, :bad_request, "Missing or invalid parameter(s)")
  end

  defp get_or_create_guest_uuid(conn) do
    case fetch_guest_uuid(conn) do
      {:ok, uuid} -> uuid
      {:error, :no_guest_uuid} -> Ecto.UUID.generate()
    end
  end

  defp fetch_guest_uuid(conn) do
    conn = fetch_cookies(conn)

    case conn.cookies[@guest_cookie] do
      nil ->
        {:error, :no_guest_uuid}

      "" ->
        {:error, :no_guest_uuid}

      value ->
        case Ecto.UUID.cast(value) do
          {:ok, uuid} -> {:ok, uuid}
          :error -> {:error, :no_guest_uuid}
        end
    end
  end

  defp put_guest_cookie(conn, guest_uuid) do
    put_resp_cookie(conn, @guest_cookie, guest_uuid,
      http_only: true,
      secure: true,
      same_site: "Strict",
      max_age: @guest_cookie_max_age,
      path: "/v2/chats/guest"
    )
  end
end
